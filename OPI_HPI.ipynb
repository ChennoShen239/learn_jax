{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "fc6f2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import quantecon as qe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "90f2e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "97ab7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "421c6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_jax(\n",
    "    R=1.01,\n",
    "    beta=0.98,\n",
    "    gamma=2,\n",
    "    w_min=0.01,\n",
    "    w_max=5,\n",
    "    w_size=150,\n",
    "    rho=0.9,\n",
    "    nu=0.1,\n",
    "    y_size=100,\n",
    "):\n",
    "    w_grid = jnp.linspace(w_min, w_max, w_size)\n",
    "    mc = qe.tauchen(n=y_size, rho=rho, sigma=nu)\n",
    "    y_grid, Q = jnp.exp(mc.state_values), jnp.array(mc.P)\n",
    "    params = (beta, R, gamma)\n",
    "    sizes = (w_size, y_size)\n",
    "    arrays = (w_grid, y_grid, Q)\n",
    "    return params, sizes, arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "573f357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(c, params):\n",
    "    beta, R, gamma = params\n",
    "    return c ** (1 - gamma) / (1 - gamma)\n",
    "\n",
    "\n",
    "u = jax.jit(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "625e5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_vmap(v, params, sizes, arrays, i, j, ip):\n",
    "    \"\"\"\n",
    "    The right-hand side of the Bellman equation before maximization, which takes\n",
    "    the form\n",
    "\n",
    "        B(w, y, w′) = u(Rw + y - w′) + β Σ_y′ v(w′, y′) Q(y, y′)\n",
    "\n",
    "    The indices are (i, j, ip) -> (w, y, w′).\n",
    "    \"\"\"\n",
    "    beta, R, gamma = params\n",
    "    w_grid, y_grid, Q = arrays\n",
    "    w, y, wp = w_grid[i], y_grid[j], w_grid[ip]\n",
    "    c = R * w + y - wp\n",
    "    EV = jnp.sum(v[ip, :] * Q[j, :])\n",
    "    ans = jnp.where(c > 0, u(c, params) + beta * EV, -jnp.inf)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "3abf1d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_1 = jax.vmap(B_vmap, in_axes=(None, None, None, None, None, None, 0))\n",
    "B_2 = jax.vmap(B_1, in_axes=(None, None, None, None, None, 0, None))\n",
    "B_vmap = jax.vmap(B_2, in_axes=(None, None, None, None, 0, None, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eca99ca",
   "metadata": {},
   "source": [
    "JAX 的 `vmap` 默认行为是：**每次 vmap 都会在结果的最前面（axis 0）插入一个新的维度。**\n",
    "\n",
    "我们来倒推一下它是怎么形成 $(i, j, ip)$ 的：\n",
    "\n",
    "### 1. 核心规则：后进先出（Last in, First out）\n",
    "*   **最内层的 vmap**（处理谁）：对应的维度会变成**最里面（最后面）的维度**。\n",
    "*   **最外层的 vmap**（处理谁）：对应的维度会变成**最外面（最前面）的维度**。\n",
    "\n",
    "---\n",
    "\n",
    "### 2. 这里的演变过程\n",
    "\n",
    "#### 第一步：最内层 `B_1` (处理 `ip`)\n",
    "*   **任务**：针对 `ip` 向量化。\n",
    "*   **动作**：算出一排结果。\n",
    "*   **此时形状**：`(N_ip,)`\n",
    "*   **对应维度**：因为只有一层，它既是第 0 维也是最后一维。\n",
    "\n",
    "#### 第二步：中间层 `B_2` (处理 `j`)\n",
    "*   **任务**：针对 `j` 向量化。\n",
    "*   **动作**：JAX 会说：“好，我针对每一个 `j` 都运行一遍 B_1（得到一个 `N_ip` 的条），然后把这些条**堆叠**起来。”\n",
    "*   **堆叠位置**：最前面 (Axis 0)。\n",
    "*   **此时形状**：`(N_j, N_ip)`\n",
    "    *   `N_j` 占据了 Axis 0。\n",
    "    *   原来的 `N_ip` 被挤到了 Axis 1。\n",
    "\n",
    "#### 第三步：最外层 `B_vmap` (处理 `i`)\n",
    "*   **任务**：针对 `i` 向量化。\n",
    "*   **动作**：JAX 会说：“好，我针对每一个 `i` 都运行一遍 B_2（得到一个 `N_j x N_ip` 的矩阵），然后把这些矩阵**堆叠**起来。”\n",
    "*   **堆叠位置**：最前面 (Axis 0)。\n",
    "*   **此时形状**：`(N_i, N_j, N_ip)`\n",
    "    *   `N_i` 占据了 Axis 0。\n",
    "    *   原来的 `N_j` 被挤到了 Axis 1。\n",
    "    *   原来的 `N_ip` 被挤到了 Axis 2。\n",
    "\n",
    "---\n",
    "\n",
    "### 3. 如果搞反了会怎样？\n",
    "\n",
    "假设你想保持 `(i, j, ip)` 的输出形状，但你把 `vmap` 顺序写反了，比如最外层处理 `ip`，最内层处理 `i`：\n",
    "\n",
    "1.  内层处理 `i` $\\rightarrow$ 输出 `(N_i)`\n",
    "2.  中层处理 `j` $\\rightarrow$ 输出 `(N_j, N_i)`\n",
    "3.  外层处理 `ip` $\\rightarrow$ 输出 `(N_ip, N_j, N_i)`\n",
    "\n",
    "**结果**：你的输出形状变成了 `(ip, j, i)`。\n",
    "**后果**：当你后面调用 `max(axis=2)` 时，你消掉的就不是“下一期资产选择 `ip`”了，而是“当前资产 `i`”，这完全破坏了 Bellman 方程的物理意义。\n",
    "\n",
    "### 总结\n",
    "\n",
    "*   你想让哪个变量出现在 Tensor 的**最后面**（最内层维度），你就必须在代码的最里层（**第一个 vmap**）去处理它。\n",
    "*   你想让哪个变量出现在 Tensor 的**最前面**（最外层维度），你就必须在代码的最外层（**最后一个 vmap**）去处理它。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "5e5aab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def B(v, params, sizes, arrays):\n",
    "    w_size, y_size = sizes\n",
    "    w_indices, y_indices = jnp.arange(w_size), jnp.arange(y_size)\n",
    "    return B_vmap(v, params, sizes, arrays, w_indices, y_indices, w_indices)\n",
    "\n",
    "\n",
    "B = jax.jit(B, static_argnums=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0f41b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T(v, params, sizes, arrays):\n",
    "    return jnp.max(B(v, params, sizes, arrays), axis=-1)\n",
    "\n",
    "\n",
    "T = jax.jit(T, static_argnums=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "cdf9f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_greedy(v, params, sizes, arrays):\n",
    "    return jnp.argmax(B(v, params, sizes, arrays), axis=-1)\n",
    "\n",
    "\n",
    "get_greedy = jax.jit(get_greedy, static_argnums=(2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94bfe23",
   "metadata": {},
   "source": [
    "Given current policy $\\sigma$, we define reward $r_\\sigma$ as:\n",
    "$$\n",
    "r_\\sigma := r(w,y,\\sigma(w,y))\n",
    "$$\n",
    "and in this case, it's the utility from consumption given this policy $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a8cacbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_r_sigma(sigma, params, sizes, arrays, i, j):\n",
    "    beta, R, gamma = params\n",
    "    w_grid, y_grid, Q = arrays\n",
    "\n",
    "    # compute r_sigma [i, j]\n",
    "    w, y, wp = w_grid[i], y_grid[j], w_grid[sigma[i, j]]\n",
    "    c = R * w + y - wp\n",
    "    r_sigma = u(c, params)\n",
    "    return r_sigma\n",
    "\n",
    "\n",
    "r_1 = jax.vmap(\n",
    "    _get_r_sigma,\n",
    "    in_axes=(None, None, None, None, None, 0),\n",
    ")\n",
    "r_sigma_vmap = jax.vmap(\n",
    "    r_1,\n",
    "    in_axes=(None, None, None, None, 0, None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "82fa803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_sigma(sigma, params, sizes, arrays):\n",
    "    w_size, y_size = sizes\n",
    "    w_indices, y_indices = jnp.arange(w_size), jnp.arange(y_size)\n",
    "    return r_sigma_vmap(sigma, params, sizes, arrays, w_indices, y_indices)\n",
    "\n",
    "\n",
    "r_sigma = jax.jit(r_sigma, static_argnums=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "5db34c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _T_sigma(v, sigma, params, sizes, arrays, i, j):\n",
    "    beta, R, gamma = params\n",
    "    w_grid, y_grid, Q = arrays\n",
    "\n",
    "    r_sigma = _get_r_sigma(sigma, params, sizes, arrays, i, j)\n",
    "    EV = jnp.sum(v[sigma[i, j], :] * Q[j, :])\n",
    "    return r_sigma + beta * EV\n",
    "\n",
    "\n",
    "T_1 = jax.vmap(\n",
    "    _T_sigma,\n",
    "    in_axes=(None, None, None, None, None, None, 0),\n",
    ")\n",
    "\n",
    "T_sigma_vmap = jax.vmap(\n",
    "    T_1,\n",
    "    in_axes=(None, None, None, None, None, 0, None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "c8728083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_sigma(v, sigma, params, sizes, arrays):\n",
    "    w_size, y_size = sizes\n",
    "    w_indices, y_indices = jnp.arange(w_size), jnp.arange(y_size)\n",
    "    return T_sigma_vmap(v, sigma, params, sizes, arrays, w_indices, y_indices)\n",
    "\n",
    "\n",
    "T_sigma = jax.jit(T_sigma, static_argnums=(3,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b05c53e",
   "metadata": {},
   "source": [
    "Now we need some extra math:\n",
    "- we want the value $v_\\sigma$ given $\\sigma$\n",
    "- we know it satisfies the Bellman equation:\n",
    "$$\n",
    "v_\\sigma (w,y) = r_\\sigma (w,y) + \\beta \\mathbb{E}_{y'|y}[v_\\sigma(\\sigma(w,y),y')]\n",
    "$$\n",
    "\n",
    "to solve this:\n",
    "+ we define $L_\\sigma$ as:\n",
    "$$\n",
    "(L_\\sigma v)(w,y) = v_\\sigma (w,y) -\\beta \\mathbb{E}_{y'|y}[v_\\sigma(\\sigma(w,y),y')]\n",
    "$$\n",
    "+ so it satisfies:\n",
    "$$\n",
    "(L_\\sigma v)(w,y) = r_\\sigma (w,y) \n",
    "$$\n",
    "+ then we have $L_\\sigma v_\\sigma = r_\\sigma$, that is, \n",
    "$$\n",
    "v_\\sigma = L_\\sigma^{-1} r_\\sigma\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e5636",
   "metadata": {},
   "source": [
    "Another note on this PI:\n",
    "+ given this fixed policy $\\sigma$, there's no $\\max$ operator here.\n",
    "+ this is purely a linear equation\n",
    "\n",
    "define $v \\in \\mathbb{R}^{n\\times 1}$, where $n$ is the number of the states in total. Then we can rewrite in matrix form:\n",
    "$$\n",
    "v = r + \\beta P_\\sigma v\n",
    "$$\n",
    "so we basically have:\n",
    "$$\n",
    "(I -\\beta P_\\sigma )v = r\n",
    "$$\n",
    "that is $L_\\sigma = I - \\beta P_\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "7db4beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _L_sigma(v, sigma, params, sizes, arrays, i, j):\n",
    "    beta, R, gamma = params\n",
    "    w_grid, y_grid, Q = arrays\n",
    "\n",
    "    ans = v[i, j] - beta * jnp.sum(v[sigma[i, j], :] * Q[j, :])\n",
    "    return ans\n",
    "\n",
    "\n",
    "L_1 = jax.vmap(_L_sigma, in_axes=(None, None, None, None, None, None, 0))\n",
    "L_sigma_vmap = jax.vmap(\n",
    "    L_1,\n",
    "    in_axes=(None, None, None, None, None, 0, None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "751d618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_sigma(v, sigma, params, sizes, arrays):\n",
    "    w_size, y_size = sizes\n",
    "    w_indices, y_indices = jnp.arange(w_size), jnp.arange(y_size)\n",
    "    return L_sigma_vmap(v, sigma, params, sizes, arrays, w_indices, y_indices)\n",
    "\n",
    "\n",
    "L_sigma = jax.jit(L_sigma, static_argnums=(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "49d27691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_v_sigma(sigma, params, sizes, arrays):\n",
    "    r_sigma_val = r_sigma(sigma, params, sizes, arrays)\n",
    "    _L_sigma = lambda v: L_sigma(v, sigma, params, sizes, arrays)\n",
    "    ans = jax.scipy.sparse.linalg.bicgstab(_L_sigma, r_sigma_val)\n",
    "    return ans[0]\n",
    "\n",
    "\n",
    "get_v_sigma = jax.jit(get_v_sigma, static_argnums=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "1cc1c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sucessive_approx_jax(T, v_0, tol=1e-8, max_iter=10000):\n",
    "    def body_fun(k_v_err):\n",
    "        k, v, err = k_v_err\n",
    "        v_new = T(v)\n",
    "        err = jnp.max(jnp.abs(v_new - v))\n",
    "        return k + 1, v_new, err\n",
    "\n",
    "    def cond_fun(k_v_err):\n",
    "        k, v, err = k_v_err\n",
    "        return jnp.logical_and(k < max_iter, err > tol)\n",
    "\n",
    "    k, v, err = jax.lax.while_loop(cond_fun, body_fun, (0, v_0, jnp.inf))\n",
    "    return v\n",
    "\n",
    "\n",
    "sucessive_approx_jax = jax.jit(sucessive_approx_jax, static_argnums=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "42b9f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OPI_update(sigma, v, m, params, sizes, arrays):\n",
    "    def update(i, v):\n",
    "        v = T_sigma(v, sigma, params, sizes, arrays)\n",
    "        return v\n",
    "\n",
    "    v = jax.lax.fori_loop(0, m, update, v)\n",
    "    return v\n",
    "\n",
    "\n",
    "OPI_update = jax.jit(OPI_update, static_argnums=(4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "c8866b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OPI_loop(\n",
    "    params,\n",
    "    sizes,\n",
    "    arrays,\n",
    "    m=50,\n",
    "    tol=1e-8,\n",
    "    max_iter=10_000,\n",
    "):\n",
    "    v_0 = jnp.zeros(sizes)\n",
    "\n",
    "    def cond_fun(k_v_err):\n",
    "        k, v, err = k_v_err\n",
    "        return jnp.logical_and(k < max_iter, err > tol)\n",
    "\n",
    "    def body_fun(k_v_err):\n",
    "        k, v, err = k_v_err\n",
    "        sigma = get_greedy(v, params, sizes, arrays)\n",
    "        v_new = OPI_update(sigma, v, m, params, sizes, arrays)\n",
    "        err = jnp.max(jnp.abs(v_new - v))\n",
    "        return k + 1, v_new, err\n",
    "\n",
    "    k, v, err = jax.lax.while_loop(\n",
    "        cond_fun,\n",
    "        body_fun,\n",
    "        (0, v_0, jnp.inf),\n",
    "    )\n",
    "    return v\n",
    "\n",
    "\n",
    "OPI_loop = jax.jit(OPI_loop, static_argnums=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "19f026be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OPI(params, sizes, arrays, m=20, tol=1e-8, max_iter=10_000):\n",
    "    sigma = OPI_loop(params, sizes, arrays, m, tol, max_iter)\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "ceea2325",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, sizes, arrays = create_model_jax()\n",
    "sigma = OPI(params, sizes, arrays).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "e9bceeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPI time: 0.2265169620513916 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "sigma = OPI(params, sizes, arrays).block_until_ready()\n",
    "end_time = time.time()\n",
    "OPI_time = end_time - start_time\n",
    "print(f\"OPI time: {OPI_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "20f7cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def howard_policy_iteration(model, maxiter=250):\n",
    "    \"\"\"\n",
    "    Implements Howard policy iteration (see dp.quantecon.org)\n",
    "    \"\"\"\n",
    "    params, sizes, arrays = model\n",
    "    σ = jnp.zeros(sizes, dtype=int)\n",
    "    i, error = 0, 1.0\n",
    "    while error > 0 and i < maxiter:\n",
    "        v_σ = get_v_sigma(σ, params, sizes, arrays)\n",
    "        σ_new = get_greedy(v_σ, params, sizes, arrays)\n",
    "        error = jnp.max(jnp.abs(σ_new - σ))\n",
    "        σ = σ_new\n",
    "        i = i + 1\n",
    "        if i % 20 == 0:\n",
    "            print(f\"Concluded loop {i} with error {error}.\")\n",
    "    return σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ce2d311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluded loop 20 with error 1.\n",
      "Concluded loop 40 with error 1.\n",
      "Concluded loop 60 with error 1.\n",
      "Concluded loop 80 with error 1.\n",
      "Concluded loop 100 with error 1.\n",
      "Concluded loop 120 with error 1.\n",
      "Concluded loop 140 with error 1.\n",
      "Concluded loop 160 with error 1.\n",
      "Concluded loop 180 with error 1.\n",
      "Concluded loop 200 with error 1.\n",
      "Concluded loop 220 with error 1.\n",
      "Concluded loop 240 with error 1.\n"
     ]
    }
   ],
   "source": [
    "sigma = howard_policy_iteration(model=(params, sizes, arrays)).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "ae3b5f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluded loop 20 with error 1.\n",
      "Concluded loop 40 with error 1.\n",
      "Concluded loop 60 with error 1.\n",
      "Concluded loop 80 with error 1.\n",
      "Concluded loop 100 with error 1.\n",
      "Concluded loop 120 with error 1.\n",
      "Concluded loop 140 with error 1.\n",
      "Concluded loop 160 with error 1.\n",
      "Concluded loop 180 with error 1.\n",
      "Concluded loop 200 with error 1.\n",
      "Concluded loop 220 with error 1.\n",
      "Concluded loop 240 with error 1.\n",
      "HPI time: 3.2087228298187256 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "sigma = howard_policy_iteration(model=(params, sizes, arrays)).block_until_ready()\n",
    "end_time = time.time()\n",
    "OPI_time = end_time - start_time\n",
    "print(f\"HPI time: {OPI_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
